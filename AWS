VPC 생성하기 (VPC)
"VPC 생성"
1. "생성할 리소스" : "VPC 등"
2. "이름 태그 자동 생성" : "자동 생성"
3. "가용 영역(AZ) 수" : "2", "첫 번째 가용 영역" : "ap-northeast-2a", "두 번째 가용 영역" : "ap-northeast-2b"
4. "퍼블릭 서브넷 수" : "2", "프라이빗 서브넷 수" : 2
5. "NAT 게이트웨이($)" : "1개의 AZ에서"
6. "VPC 엔드포인트" : "없음"

EC2 역할 생성하기 (IAM > 역할)
"역할 생성"
1. "신뢰할 수 있는 엔터티 유형" : "AWS 서비스"
2. "서비스 또는 사용 사례" : "EC2", "사용 사례" : "EC2"
3. "권한 정책" : "AdministratorAccess"
4. "역할 이름" : "AdministratorAccess-EC2-Role"

EC2 생성하기 (인스턴스)
"인스턴스 시작"
1. "이름" : "my-bastion"
2. "Amazon Machine Image(AMI)" : "Amazon Linux 2 AMI (HVM) - Kernel 5.10, SSD Volume Type"
3. "인스턴스 유형" : "t2.micro"
4. "새 키 페어 생성"
5. "네트워크 설정" : "편집", "VPC" : <아까 만든 VPC>
6. "서브넷" : "public1-ap-northeast-2a"
7. "퍼블릭 IP 자동 할당" : "활성화"
8. "방화벽(보안 그룹)" : "보안 그룹 생성"
9. "IAM 인스턴스 프로파일" : "AdministratorAccess-EC2-Role"
10. "메타데이터 버전" : "V1 및 V2(토큰 선택 사항)"

탄력적 IP 생성하기 (탄력적 IP 주소)
"탄력적 IP 주소 할당"
1. "탄력적 IP 주소가 할당되었습니다." : "이 탄력적 IP 주소 연결"
2. "인스턴스" : <아까 만든 EC2>
3. "프라이빗 IP 주소" : <아까 만든 EC2 프라이빗 IP 주소>

EC2 재부팅하기 (인스턴스)
<만든 인스턴스 체크> -> "인스턴스 상태" -> "재부팅"

EC2 터미널 연결하기 (터미널)
"터미널"
1. "ssh -i <키 페어> ec2-user@<인스턴스 퍼블릭 IP 주소>"

EC2 패키지 설치하기 (터미널)
"터미널"
1. "sudo su" : "루트 사용자로 전환"
2. "https://docs.aws.amazon.com/ko_kr/cli/latest/userguide/getting-started-install.html" : "링크 들어가서 AWS CLI Linux 설치"
3. "yum install jq -y" : jq 설치
4. "yum install curl" : curl 설치

S3 버킷 생성하기 (Amazon S3 > 버킷)
"버킷 생성하기"
1. "버킷 이름" : "my-data-s3-<비번호>"

S3 버킷 폴더 생성하기 (Amazon S3 > 버킷 > my-data-s3-<비번호>)
"폴더 생성하기'
1. "폴더 이름" : "data"
"폴더 생성하기"
2. "폴더 이름" : "script"
"폴더 생성하기"
3. "폴더 이름" : "output"

S3 버킷 폴더 안에 배포 파일 생성하기 (Amazon S3 > 버킷 > my-data-s3-<비번호>)
"data/"
1. "data.csv" 업로드 하기

Lambda 역할 생성하기 (IAM > 역할)
"역할 생성"
1. "신뢰할 수 있는 엔터티 유형" : "AWS 서비스"
2. "서비스 또는 사용 사례" : "Lambda", "사용 사례" : "Lambda"
3. "권한 정책" : "AdministratorAccess"
4. "역할 이름" : "AdministratorAccess-Lambda-Role"

Lambda 함수 생성하기 (Lambda > 함수)
"함수 생성"
1. "다음 옵션 중 하나를 선택하여 함수를 생성합니다." : "새로 작성"
2. "함수 이름" : "data-function"
3. "런타임" : "Python 3.9"
4. "실행 역할" : "기존 역할 사용"
5. "기존 역할" : "AdministratorAccess-Lambda-Role"

Lambda 함수에서 트리거 생성하기 (Lambda > 함수 > data-function)
"트리거 추가"
1. "트리거 구성" : "S3"
2. "버킷" : "s3/my-data-s3-<비번호>"
3. "이벤트 유형" : "PUT"
4. "접두사" : "data/"
5. "접미사" : ".csv"

Lambda 함수에서 제한 시간 1분으로 수정하기 (Lambda > 함수 > data-function)
"구성" -> "일반 구성" -> "편집"
1. "제한 시간" : "1분"

Lambda 함수에서 배포파일 코드 소스 수정하기 (Lambda > 함수 > data-function)
"코드" -> "코드 소스"
1. "data-function.py" 파일 수정하기
2. "s3://my-data-s3-101/script/script.py" : "s3://my-data-s3-<비번호>/script/script.py" 이렇게 수정하기
3. 수정한 파일을 복사하여 Lambda 함수 코드 소스에 붙여넣기
4. "Deploy" 잊지 않기

Lambda 함수에서 배포파일 코드 소스 이름 수정하기 (Lambda > 함수 > data-function)
"코드" -> "코드 소스"
1. "lambda_function.py" : "data-function.py" 로 이름 수정하기

Lambda 함수에서 핸들러 수정하기 (Lambda > 함수 > data-function)
"코드" -> "런타임 설정" -> "편집"
1. "핸들러" : "<파일 이름>.<함수 이름>"

Lambda 함수에서 테스트 이벤트 생성하기 (Lambda > 함수 > data-function)
"테스트"
1. "이벤트 작업 테스트" : "새 이벤트 생성"
2. "이벤트 이름" : 아무거나
3. "이벤트 JSON" : 아래내용을 복사하고 붙여넣는다
{
  "Records": [
    {
      "s3": {
        "bucket": {
          "name": "my-data-s3-<비번호>"
        },
        "object": {
          "key": "data/data.csv"
        }
      }
    }
  ]
}
4. 코드 수정하기
5. "테스트" 누르기

Glue job 역할 생성하기 (IAM > 역할)
"역할 생성"
1. "신뢰할 수 있는 엔터티 유형" : "AWS 서비스"
2. "서비스 또는 사용 사례" : "Glue", "사용 사례" : "Glue"
3. "권한 정책" : "AdministratorAccess"
4. "역할 이름" : "AdministratorAccess-Glue-Role"

Glue job 생성하기 (AWS Glue > Jobs)
"ETL jobs" -> "Create job" -> "Script editor"
1. "Engine" : "Spark"
2. "Options" : "Start fresh"

Glue job 생성하기, 코드 수정하기 ("Script", "Job details", "Runs", "Data quality", "Schedules", "Version Control")
"Script"
1. "script.py" 배포파일 복사하여 "script"에 붙여넣기
2. "s3://my-data-s3-101/data/data.csv" : "s3://my-data-s3-<비번호>/data/data.csv" 이렇게 수정하기\
3. "s3://my-data-s3-101/output/" : "s3://my-data-s3-<비번호>/output/" 이렇게 수정하기

Glue job 생성하기 ("Script", "Job details", "Runs", "Data quality", "Schedules", "Version Control")
"Job details"
1. "Name" : "my-glue-job"
2. "IAM Role" : "AdministratorAccess-Glue-Role"
3. "Script filename" : "script.py"
4. "Script path" : "s3://my-data-s3-<비번호>/script/"

Glue job 실행하기 ("Script", "Job details", "Runs", "Data quality", "Schedules", "Version Control")
"Runs"
1. "Run" 누르기
2. "S3"에 있는 "output" 폴더 안 확인하기
3. "S3"에 있는 "script" 폴더 안 확인하기

Database 생성하기 (AWS Glue > Databases)
"Add database"
1. "Name" : "my-database"

Crawlers 생성하기 (AWS Glue > Crawlers)
"Create crawler"
1. "Name" : "convert-crawler"
2. "Data source configuration" : "Not yet"
3. "Data sources" : "Add a data source"
4. "S3 path" : "s3://my-data-s3-<비번호>/output/" (수정하기)
5. "Subsequent crawler runs" : "Crawl all sub-folders"
6. "Existing IAM role" : "AdministratorAccess-Glue-Role"
7. "Target database" : "my-database"
8. "Table name prefix" : "convert_"

Crawlers 실행하기 (AWS Glue > Crawlers > convert-crawler) ("Crawler runs", "Schedule" "Data sources", "Classifiers", "Tags")
"Crawler runs"
1. "Run crawler" 누른다

Tables 생성 확인하기 ("AWS Glue" > "Tables")
"Tables"
1. "Tables" 생성 확인

Athena 생성하기 (Amazon Athena > 쿼리 편집기)
"설정" -> "관리"
1. "Location of query result" : "s3://my-data-s3-<비번호>/man/"
2. "편집기"에 아래 내용을 복사하고 붙여넣는다
select count(*) from convert_output
where sex='boy' and year between '1932' and '1967'
3. "실행"을 누른다
4. "결과" : "36000"
5. "Location of query result" : "s3://my-data-s3-<비번호>/woman/"
6. "편집기"에 아래 내용을 복사하고 붙여넣는다
select count(*) from convert_output
where sex='girl' and year like '20%'
7. "실행"을 누른다
8. "결과" : "9000"
9. "S3"에 들어가서 "man"과 "woman" 폴더 생성 확인하기

SQS 생성하기 (Amazon SQS > 대기열)
"대기열 생성"
1. "이름" : "my-queue"
2. "URL" 생성 확인하기

EventBridge 생성하기 (Amazon EventBridge > 규칙)
"규칙 생성"
1. "이름" : "s3-upload-rule"
2. "규칙 유형" : "이벤트 패턴이 있는 규칙"
3. "방법" : "사용자 지정 패턴(JSON 편집기)"
4. "이벤트 패턴" : 아래 내용을 복사하고 붙여넣는다 (수정하기)
{
  "source": ["aws.s3"],
  "detail-type": ["Object Created"],
  "detail": {
    "bucket": {
      "name": ["my-data-s3-<비번호>"]
    },
    "object": {
      "key" : [{"prefix" : "man/"}, {"prefix" : "woman/"}]
    }
  }
}
5. "대상 선택" : "SQS 대기열"
6. "대기열" : "my-queue"

S3 버킷에서 EventBridge 활성화 하기 (Amazon S3 > 버킷 > my-data-s3-<비번호>), ("객체", "속성", "권한", "지표", "관리", "액세스 지점")
"속성"
1. "Amazon EventBridge" : "활성화"

메시지 폴링하기 (Amazon Athena > 쿼리 편집기) ("편집기", "최근 쿼리", "저장된 쿼리", "설정")
"설정" -> "관리"
1. "Location of query result" -> "s3://my-data-s3-5321/man/"
"편집기"
2. 아래 내용을 복사하고 붙여넣는다
select count(*) from convert_output
where sex='boy' and year between '1932' and '1967'
3. "다시 실행" 누르기
4. "SQS"에 접속하여 (Amazon SQS > 대기열 > my-queue)
5. "메시지 전송 및 수신" 누르기 (Amazon SQS > 대기열 > my-queue > 메시지 전송 및 수신)
6. "메시지 폴링" 누르기 ("메시지 폴링" 했는데 안될경우 : "Crawlers" 다시 실행)

대시보드 생성하기 (CloudWatch > Dashboards)
"대시보드 생성"
1. "대시보드 이름" : "my-dashboard"
2. "위젯 유형" : "행"
3. "FunctionName" : "data-function", "리소스 (Resource)" : "data-function", "지표 이름" : "ConcurrentExecutions" 체크
4. "위젯 생성" 누르기
5. "..." 세로로 되있는거 누르기
6. "편집" 누르기
7. "통계" : "평균", "기간" : "1분"
8. "ConcurrentExecutions" 마우스 갖다 대기
9. "제목 편집" 누르기
10. "ConcurrentExecutions"을 "Lambda_Execution"으로 수정하기
11. "저장" 누르기

대시보드, 지표 생성하기 (CloudWatch > Dashboards)
"대시보드 생성"
1. "대시보드 이름" : "my-dashboard"
2. "데이터 유형" : "지표"
3. "위젯 유형" : "행"
4. "FunctionName" : "data-function", "리소스 (Resource)" : "data-function", "지표 이름" : "ConcurrentExecutions" 체크
5. "위젯 생성" 누르기
6. "..." 세로로 되있는거 누르기
7. "편집" 누르기
8. "통계" : "평균", "기간" : "1분"
9. "위젯 업데이트"
10. "ConcurrentExecutions" 마우스 갖다 대기
11. "제목 편집" 누르기
12. "ConcurrentExecutions"를 "Lambda_Execution"으로 수정하기
13. "저장" 누르기

지표 생성하기 (CloudWatch > Dashboards > my-dashboard)
"+" 누르기
1. "데이터 유형" : "지표"
2. "위젯 유형" : "행"
3. "QueueName" : "my-queue", "지표 이름" : "NumberOfMessagesReceived"
4. "위젯 생성" 누르기
5. "..." 세로로 되있는거 누르기
6. "편집" 누르기
7. "통계" : "평균", "기간" : "1분"
8. "위젯 업데이트"
9. "NumberOfMessagesReceived" 마우스 갖다 대기
10. "제목 편집" 누르기
11. "NumberOfMessagesReceived"를 "SQS_Received"로 수정하기
12. "저장" 누르기



















